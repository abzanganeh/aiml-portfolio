<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Applications - Project Details</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            position: fixed;
            top: 0;
            width: 100%;
            z-index: 1000;
            transition: all 0.3s ease;
        }

        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 0;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: white;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            color: white;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .nav-links a:hover {
            color: #ffd700;
        }

        /* Main Content */
        main {
            margin-top: 80px;
            padding: 2rem 0;
        }

        .project-header {
            text-align: center;
            color: white;
            padding: 2rem 0;
        }

        .project-header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        .project-header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .content-section {
            background: white;
            margin: 2rem 0;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .content-section h2 {
            color: #667eea;
            margin-bottom: 1rem;
            font-size: 1.8rem;
        }

        .content-section h3 {
            color: #333;
            margin: 1.5rem 0 1rem 0;
            font-size: 1.3rem;
        }

        .content-section p {
            margin-bottom: 1rem;
            text-align: justify;
        }

        .code-block {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }

        .back-link {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 5px;
            margin: 1rem 0;
            transition: background 0.3s ease;
        }

        .back-link:hover {
            background: #764ba2;
        }

        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin: 1rem 0;
        }

        .tech-tag {
            background: #667eea;
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.9rem;
        }

        .project-links {
            display: flex;
            gap: 1rem;
            margin: 1rem 0;
        }

        .project-link {
            background: #667eea;
            color: white;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 5px;
            transition: background 0.3s ease;
        }

        .project-link:hover {
            background: #764ba2;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <nav class="container">
            <div class="logo">Alireza Barzin Zanganeh</div>
            <ul class="nav-links">
                <li><a href="../../index.html">Home</a></li>
                <li><a href="../../index.html#about">About</a></li>
                <li><a href="../../index.html#skills">Skills</a></li>
                <li><a href="../../index.html#projects">Projects</a></li>
                <li><a href="../../index.html#learning">Learning</a></li>
                <li><a href="../../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <!-- Main Content -->
    <main>
        <div class="project-header">
            <div class="container">
                <h1>ü§ñ Large Language Model Applications</h1>
                <p>End-to-end AI applications leveraging transformer architectures</p>
            </div>
        </div>

        <div class="container">
            <a href="../../index.html#projects" class="back-link">‚Üê Back to Projects</a>

            <div class="content-section">
                <h2>Project Overview</h2>
                <p>
                    This project demonstrates the development of sophisticated Large Language Model (LLM) applications 
                    using state-of-the-art transformer architectures. The implementations include custom fine-tuning, 
                    prompt engineering techniques, and production-ready deployment strategies for various NLP tasks.
                </p>
                
                <h3>Technologies Used</h3>
                <div class="tech-stack">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">Transformers</span>
                    <span class="tech-tag">Hugging Face</span>
                    <span class="tech-tag">OpenAI API</span>
                    <span class="tech-tag">LangChain</span>
                    <span class="tech-tag">FastAPI</span>
                    <span class="tech-tag">Docker</span>
                </div>

                <div class="project-links">
                    <a href="https://github.com/abzanganeh" class="project-link">View on GitHub</a>
                    <a href="#" class="project-link">Live Application</a>
                </div>
            </div>

            <div class="content-section">
                <h2>Key Applications</h2>
                
                <h3>1. Document Question-Answering System</h3>
                <p>
                    Built a sophisticated QA system that can analyze and answer questions about large documents 
                    using retrieval-augmented generation (RAG) techniques.
                </p>

                <h3>2. Content Generation Pipeline</h3>
                <p>
                    Developed an automated content generation system for various formats including:
                </p>
                <ul>
                    <li>Technical documentation</li>
                    <li>Marketing copy</li>
                    <li>Code documentation</li>
                    <li>Educational materials</li>
                </ul>

                <h3>3. Sentiment Analysis & Classification</h3>
                <p>
                    Implemented advanced sentiment analysis models for social media monitoring and customer feedback analysis.
                </p>
            </div>

            <div class="content-section">
                <h2>Advanced Features</h2>
                <ul>
                    <li><strong>Custom Fine-Tuning:</strong> Domain-specific model adaptation using LoRA and QLoRA techniques</li>
                    <li><strong>Prompt Engineering:</strong> Advanced prompting strategies including chain-of-thought and few-shot learning</li>
                    <li><strong>RAG Implementation:</strong> Retrieval-augmented generation with vector databases</li>
                    <li><strong>Multi-Modal Capabilities:</strong> Text-to-image and image-to-text generation</li>
                    <li><strong>API Integration:</strong> Seamless integration with OpenAI, Claude, and open-source models</li>
                    <li><strong>Production Deployment:</strong> Scalable deployment with load balancing and monitoring</li>
                </ul>
            </div>

            <div class="content-section">
                <h2>Implementation Example</h2>
                <div class="code-block">
# RAG-based Document QA System
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
import openai

class DocumentQASystem:
    def __init__(self, documents, openai_api_key):
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        self.vectorstore = self.create_vectorstore(documents)
        self.llm = OpenAI(openai_api_key=openai_api_key, temperature=0)
        self.qa_chain = self.setup_qa_chain()
    
    def create_vectorstore(self, documents):
        """Create vector store from documents"""
        vectorstore = FAISS.from_documents(
            documents, 
            self.embeddings
        )
        return vectorstore
    
    def setup_qa_chain(self):
        """Setup the QA chain with retrieval"""
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_kwargs={"k": 3}
            ),
            return_source_documents=True
        )
        return qa_chain
    
    def answer_question(self, question):
        """Answer a question about the documents"""
        result = self.qa_chain({"query": question})
        return {
            "answer": result["result"],
            "sources": result["source_documents"]
        }

# Advanced Prompt Engineering
class PromptEngineer:
    def __init__(self):
        self.templates = {
            "chain_of_thought": """
Let's think about this step by step:

Question: {question}

Step 1: Identify the key components
Step 2: Analyze the relationships
Step 3: Apply relevant knowledge
Step 4: Draw conclusions

Answer:
            """,
            
            "few_shot": """
Here are some examples of similar problems:

Example 1: {example1}
Solution: {solution1}

Example 2: {example2}
Solution: {solution2}

Now solve this problem:
Question: {question}
Solution:
            """
        }
    
    def generate_prompt(self, template_type, **kwargs):
        return self.templates[template_type].format(**kwargs)

# Usage Example
qa_system = DocumentQASystem(documents, openai_api_key)
response = qa_system.answer_question("What are the main findings?")
print(f"Answer: {response['answer']}")
                </div>
            </div>

            <a href="../../index.html#projects" class="back-link">‚Üê Back to Projects</a>
        </div>
    </main>

    <script>
        // Header background change on scroll
        window.addEventListener('scroll', function() {
            const header = document.querySelector('header');
            if (window.scrollY > 50) {
                header.style.background = 'rgba(255, 255, 255, 0.95)';
                header.style.color = '#333';
            } else {
                header.style.background = 'rgba(255, 255, 255, 0.1)';
                header.style.color = 'white';
            }
        });
    </script>
</body>
</html>
