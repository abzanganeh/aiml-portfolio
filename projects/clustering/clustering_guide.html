<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clustering Complete Guide</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
    <link rel="stylesheet" href="../../assets/css/decision_tree_regression.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js"></script>
    
</head>
<body>
    <div style="
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
        color: white;
        padding: 12px 20px;
        text-align: center;
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        z-index: 1000;
        box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        font-size: 14px;
        border-bottom: 2px solid rgba(255,255,255,0.2);
    ">
        <span style="margin-right: 10px;">🚧</span>
        <strong>Website Under Development:</strong> 
        We experienced some downtime recently. Some links may be broken and topics incomplete - working to fix everything gradually. 
        <span style="margin-left: 10px;">Thank you for your patience! 🙏</span>
        <button onclick="this.parentElement.style.display='none'" style="
            background: rgba(255,255,255,0.2);
            border: none;
            color: white;
            margin-left: 15px;
            padding: 4px 8px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
        ">✕</button>
    </div>

    <header class="azbn-header" style="top: 50px;">
        <nav class="azbn-nav" style="top: 50px;">
            <div class="azbn-container" style="display: flex; justify-content: space-between; align-items: center;">
                <a href="../" style="text-decoration: none; color: #4f46e5; display: flex; align-items: center; gap: 0.5rem;">
                    <img src="../../assets/images/logo.png" alt="Logo" style="height: 40px;">
                </a>

                <div class="azbn-links">
                    <a href="../../#home">Home</a>
                    <a href="../../#about">About</a>
                    <a href="../../tutorials/">Tutorials</a>
                    <a href="../../#projects">Projects</a>
                    <a href="../../#contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main style="padding-top: 150px;">
        <div class="container">
        <h1>🎯 Complete Guide to Clustering</h1>
        
        <h2>📚 What is Clustering?</h2>
        <div class="content-section">
            <p>Clustering is an unsupervised machine learning technique that groups similar data points together based on their characteristics. Unlike supervised learning, clustering doesn't require labeled data - it discovers hidden patterns and structures within the dataset automatically.</p>
            
            <p>The goal is to maximize intra-cluster similarity (points within the same cluster are similar) while minimizing inter-cluster similarity (points in different clusters are different).</p>
        </div>
        
        <h2>🔍 Types of Clustering Algorithms</h2>
        
        <div class="algorithm-grid">
            <div class="algorithm-card">
                <h3>🎯 K-Means Clustering</h3>
                <p><strong>Type:</strong> Centroid-based</p>
                <p><strong>How it works:</strong> Partitions data into k clusters by minimizing within-cluster sum of squares.</p>
                <p><strong>Best for:</strong> Spherical clusters, numerical data</p>
                <p><strong>Complexity:</strong> O(n·k·i·d) where n=samples, k=clusters, i=iterations, d=dimensions</p>
            </div>
            
            <div class="algorithm-card">
                <h3>🌳 Hierarchical Clustering</h3>
                <p><strong>Type:</strong> Hierarchy-based</p>
                <p><strong>How it works:</strong> Creates tree-like cluster structure (dendrogram) by merging or splitting clusters.</p>
                <p><strong>Best for:</strong> When you don't know the number of clusters</p>
                <p><strong>Complexity:</strong> O(n³) for agglomerative</p>
            </div>
            
            <div class="algorithm-card">
                <h3>🌌 DBSCAN</h3>
                <p><strong>Type:</strong> Density-based</p>
                <p><strong>How it works:</strong> Groups points that are closely packed while marking outliers in low-density regions.</p>
                <p><strong>Best for:</strong> Irregular shapes, handling noise/outliers</p>
                <p><strong>Complexity:</strong> O(n log n) with spatial indexing</p>
            </div>
            
            <div class="algorithm-card">
                <h3>🎲 Gaussian Mixture Models</h3>
                <p><strong>Type:</strong> Distribution-based</p>
                <p><strong>How it works:</strong> Assumes data comes from mixture of Gaussian distributions.</p>
                <p><strong>Best for:</strong> Soft clustering, probabilistic assignments</p>
                <p><strong>Complexity:</strong> O(n·k·i·d)</p>
            </div>
        </div>
        
        <h2>🎯 K-Means Algorithm Deep Dive</h2>
        
        <div class="example-box">
            <h3>Algorithm Steps:</h3>
            <ol>
                <li><strong>Initialize:</strong> Choose k cluster centers randomly</li>
                <li><strong>Assign:</strong> Assign each point to nearest cluster center</li>
                <li><strong>Update:</strong> Recalculate cluster centers as mean of assigned points</li>
                <li><strong>Repeat:</strong> Steps 2-3 until convergence</li>
            </ol>
        </div>

        <div class="formula">
            <strong>Distance Formula (Euclidean):</strong><br>
            d(x, y) = √[(x₁-y₁)² + (x₂-y₂)² + ... + (xₙ-yₙ)²]
        </div>

        <div class="formula">
            <strong>Centroid Update:</strong><br>
            μₖ = (1/|Cₖ|) Σ(xᵢ ∈ Cₖ) xᵢ
        </div>
        
        <h2>💻 Python Implementation</h2>
        
        <h3>K-Means from Scratch</h3>
        <div class="code-block">
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

class KMeans:
    def __init__(self, k=3, max_iters=100, random_state=None):
        self.k = k
        self.max_iters = max_iters
        self.random_state = random_state
        
    def fit(self, X):
        if self.random_state:
            np.random.seed(self.random_state)
            
        # Initialize centroids randomly
        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]
        
        for _ in range(self.max_iters):
            # Assign points to closest centroid
            distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))
            self.labels = np.argmin(distances, axis=0)
            
            # Update centroids
            new_centroids = np.array([X[self.labels == k].mean(axis=0) for k in range(self.k)])
            
            # Check for convergence
            if np.allclose(self.centroids, new_centroids):
                break
                
            self.centroids = new_centroids
            
        return self
    
    def predict(self, X):
        distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))
        return np.argmin(distances, axis=0)

# Example usage
X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

# Fit K-means
kmeans = KMeans(k=4, random_state=0)
kmeans.fit(X)

# Plot results
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', alpha=0.6)
plt.title('True Clusters')

plt.subplot(1, 2, 2)
plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels, cmap='viridis', alpha=0.6)
plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], 
           c='red', marker='x', s=200, linewidths=3)
plt.title('K-Means Results')
plt.show()
        </div>
        
        <h3>Using Scikit-learn</h3>
        <div class="code-block">
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.preprocessing import StandardScaler

# Load and prepare data
X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)
X_scaled = StandardScaler().fit_transform(X)

# Compare different clustering algorithms
algorithms = {
    'K-Means': KMeans(n_clusters=4, random_state=0),
    'DBSCAN': DBSCAN(eps=0.3, min_samples=10),
    'Hierarchical': AgglomerativeClustering(n_clusters=4),
    'Gaussian Mixture': GaussianMixture(n_components=4, random_state=0)
}

results = {}
for name, algorithm in algorithms.items():
    # Fit the algorithm
    if name == 'Gaussian Mixture':
        labels = algorithm.fit_predict(X_scaled)
    else:
        labels = algorithm.fit_predict(X_scaled)
    
    # Calculate metrics
    silhouette = silhouette_score(X_scaled, labels)
    ari = adjusted_rand_score(y_true, labels)
    
    results[name] = {
        'labels': labels,
        'silhouette': silhouette,
        'ari': ari
    }
    
    print(f"{name}:")
    print(f"  Silhouette Score: {silhouette:.3f}")
    print(f"  Adjusted Rand Index: {ari:.3f}")
    print()
        </div>
        
        <h2>📊 Clustering Evaluation Metrics</h2>
        
        <div class="algorithm-grid">
            <div class="algorithm-card">
                <h3>📏 Silhouette Score</h3>
                <p>Measures how similar points are to their own cluster vs. other clusters</p>
                <p><strong>Range:</strong> [-1, 1]</p>
                <p><strong>Higher is better</strong></p>
                <div class="formula">s = (b - a) / max(a, b)</div>
            </div>
            
            <div class="algorithm-card">
                <h3>📐 Within-Cluster Sum of Squares (WCSS)</h3>
                <p>Sum of squared distances of points to their cluster centroid</p>
                <p><strong>Lower is better</strong></p>
                <p>Used in elbow method for optimal k</p>
            </div>
            
            <div class="algorithm-card">
                <h3>🎯 Adjusted Rand Index (ARI)</h3>
                <p>Measures similarity between predicted and true clusters</p>
                <p><strong>Range:</strong> [-1, 1]</p>
                <p><strong>Higher is better</strong></p>
            </div>
            
            <div class="algorithm-card">
                <h3>📈 Calinski-Harabasz Index</h3>
                <p>Ratio of sum of between-cluster dispersion to within-cluster dispersion</p>
                <p><strong>Higher is better</strong></p>
                <p>Good for determining optimal number of clusters</p>
            </div>
        </div>
        
        <h2>🔧 Practical Tips</h2>
        
        <div class="example-box">
            <h3>✅ Best Practices:</h3>
            <ul>
                <li><strong>🎯 Choose the right algorithm:</strong> K-means for spherical clusters, DBSCAN for irregular shapes</li>
                <li><strong>📊 Scale your data:</strong> Normalize features for distance-based algorithms</li>
                <li><strong>🔍 Determine optimal k:</strong> Use elbow method, silhouette analysis, or gap statistic</li>
                <li><strong>🎲 Handle initialization:</strong> Run multiple times with different random seeds</li>
                <li><strong>📈 Validate results:</strong> Use multiple evaluation metrics</li>
                <li><strong>🔬 Domain knowledge:</strong> Incorporate business understanding</li>
            </ul>
        </div>
        
        <h2>🚀 Real-World Applications</h2>
        
        <div class="algorithm-grid">
            <div class="algorithm-card">
                <h4>🛒 Customer Segmentation</h4>
                <p>Group customers by purchasing behavior for targeted marketing</p>
            </div>
            
            <div class="algorithm-card">
                <h4>🧬 Gene Analysis</h4>
                <p>Identify gene expression patterns and biological pathways</p>
            </div>
            
            <div class="algorithm-card">
                <h4>🖼️ Image Segmentation</h4>
                <p>Partition images into meaningful regions for computer vision</p>
            </div>
            
            <div class="algorithm-card">
                <h4>📰 Document Clustering</h4>
                <p>Group similar documents for organization and recommendation</p>
            </div>
            
            <div class="algorithm-card">
                <h4>🌐 Social Network Analysis</h4>
                <p>Detect communities and influential groups in networks</p>
            </div>
            
            <div class="algorithm-card">
                <h4>🏥 Medical Diagnosis</h4>
                <p>Group patients with similar symptoms for treatment planning</p>
            </div>
        </div>
        
        <div style="text-align: center; margin-top: 3rem;">
            <a href="../../tutorials" class="back-link">← Back to Tutorials</a>
        </div>
    </div>
    </main>
</body>
</html>
