<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decision Trees Guide - Learning Resources</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            position: fixed;
            top: 0;
            width: 100%;
            z-index: 1000;
            transition: all 0.3s ease;
        }

        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 0;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: white;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            color: white;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .nav-links a:hover {
            color: #ffd700;
        }

        /* Main Content */
        main {
            margin-top: 80px;
            padding: 2rem 0;
        }

        .learning-header {
            text-align: center;
            color: white;
            padding: 2rem 0;
        }

        .learning-header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        .learning-header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .content-section {
            background: white;
            margin: 2rem 0;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .content-section h2 {
            color: #667eea;
            margin-bottom: 1rem;
            font-size: 1.8rem;
        }

        .content-section h3 {
            color: #333;
            margin: 1.5rem 0 1rem 0;
            font-size: 1.3rem;
        }

        .content-section p {
            margin-bottom: 1rem;
            text-align: justify;
        }

        .code-block {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .formula {
            background: #f0f8ff;
            border-left: 4px solid #667eea;
            padding: 1rem;
            margin: 1rem 0;
            font-style: italic;
        }

        .back-link {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 5px;
            margin: 1rem 0;
            transition: background 0.3s ease;
        }

        .back-link:hover {
            background: #764ba2;
        }

        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1rem;
        }

        li {
            margin-bottom: 0.5rem;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <nav class="container">
            <div class="logo">Alireza Barzin Zanganeh</div>
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#skills">Skills</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#learning">Learning</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <!-- Main Content -->
    <main>
        <div class="learning-header">
            <div class="container">
                <h1>üå≥ Decision Trees</h1>
                <p>Understanding tree-based algorithms and ensemble methods</p>
            </div>
        </div>

        <div class="container">
            <a href="../index.html#learning" class="back-link">‚Üê Back to Learning Resources</a>

            <div class="content-section">
                <h2>Introduction to Decision Trees</h2>
                <p>
                    Decision trees are a type of supervised learning algorithm that can be used for both classification 
                    and regression tasks. They work by creating a model that predicts the value of a target variable 
                    by learning simple decision rules inferred from the data features. The tree structure represents 
                    decisions and their possible consequences.
                </p>
                
                <h3>Key Characteristics</h3>
                <ul>
                    <li><strong>Interpretable:</strong> Easy to understand and visualize</li>
                    <li><strong>Non-parametric:</strong> No assumptions about data distribution</li>
                    <li><strong>Handles mixed data:</strong> Works with both numerical and categorical features</li>
                    <li><strong>Feature selection:</strong> Automatically identifies important features</li>
                </ul>
            </div>

            <div class="content-section">
                <h2>How Decision Trees Work</h2>
                
                <h3>Tree Structure</h3>
                <ul>
                    <li><strong>Root Node:</strong> The topmost node representing the entire dataset</li>
                    <li><strong>Internal Nodes:</strong> Nodes with decision rules (splits)</li>
                    <li><strong>Leaf Nodes:</strong> Terminal nodes with final predictions</li>
                    <li><strong>Branches:</strong> Connections representing outcomes of decisions</li>
                </ul>

                <h3>Splitting Criteria</h3>
                <p>For classification tasks:</p>
                <ul>
                    <li><strong>Gini Impurity:</strong> Measures probability of incorrect classification</li>
                    <li><strong>Entropy:</strong> Measures disorder or randomness in the data</li>
                    <li><strong>Information Gain:</strong> Reduction in entropy after a split</li>
                </ul>

                <div class="formula">
                    Gini Impurity = 1 - Œ£(p_i)¬≤ <br>
                    Entropy = -Œ£(p_i √ó log‚ÇÇ(p_i)) <br>
                    Information Gain = Entropy(parent) - Œ£(weighted_avg √ó Entropy(children))
                </div>
            </div>

            <div class="content-section">
                <h2>Implementation Example</h2>
                <p>Here's a simple decision tree implementation using scikit-learn:</p>
                
                <div class="code-block">
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Load and prepare data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
dt_model = DecisionTreeClassifier(
    criterion='gini',        # or 'entropy'
    max_depth=5,            # prevent overfitting
    min_samples_split=10,   # minimum samples to split
    min_samples_leaf=5,     # minimum samples in leaf
    random_state=42
)

dt_model.fit(X_train, y_train)

# Make predictions
y_pred = dt_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print(classification_report(y_test, y_pred))

# Display tree rules (text format)
tree_rules = export_text(dt_model, feature_names=feature_names)
print(tree_rules)
                </div>
            </div>

            <div class="content-section">
                <h2>Ensemble Methods</h2>
                
                <h3>Random Forest</h3>
                <p>
                    Combines multiple decision trees using bootstrap aggregating (bagging). Each tree is trained 
                    on a random subset of data and features, reducing overfitting and improving generalization.
                </p>

                <h3>Gradient Boosting</h3>
                <p>
                    Builds trees sequentially, where each new tree corrects errors made by previous trees. 
                    Popular implementations include XGBoost, LightGBM, and CatBoost.
                </p>

                <div class="code-block">
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Gradient Boosting
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
                </div>
            </div>

            <div class="content-section">
                <h2>Advantages and Disadvantages</h2>
                
                <h3>Advantages</h3>
                <ul>
                    <li>Easy to understand and interpret</li>
                    <li>Requires little data preparation</li>
                    <li>Handles both numerical and categorical data</li>
                    <li>Can model non-linear relationships</li>
                    <li>Automatic feature selection</li>
                    <li>Missing values handling</li>
                </ul>

                <h3>Disadvantages</h3>
                <ul>
                    <li>Prone to overfitting (especially deep trees)</li>
                    <li>Unstable - small changes in data can result in different trees</li>
                    <li>Biased toward features with more levels</li>
                    <li>Poor performance on linear relationships</li>
                    <li>Difficulty handling missing values in some implementations</li>
                </ul>
            </div>

            <div class="content-section">
                <h2>Best Practices</h2>
                <ul>
                    <li><strong>Pruning:</strong> Use max_depth, min_samples_split to prevent overfitting</li>
                    <li><strong>Cross-validation:</strong> Use k-fold CV to evaluate model performance</li>
                    <li><strong>Feature importance:</strong> Analyze which features are most important</li>
                    <li><strong>Ensemble methods:</strong> Use Random Forest or Gradient Boosting for better performance</li>
                    <li><strong>Data preprocessing:</strong> Handle missing values and outliers appropriately</li>
                    <li><strong>Visualization:</strong> Plot the tree to understand decision rules</li>
                </ul>
            </div>

            <a href="../index.html#learning" class="back-link">‚Üê Back to Learning Resources</a>
        </div>
    </main>

    <script>
        // Header background change on scroll
        window.addEventListener('scroll', function() {
            const header = document.querySelector('header');
            if (window.scrollY > 50) {
                header.style.background = 'rgba(255, 255, 255, 0.95)';
                header.style.color = '#333';
            } else {
                header.style.background = 'rgba(255, 255, 255, 0.1)';
                header.style.color = 'white';
            }
        });
    </script>
</body>
</html>
