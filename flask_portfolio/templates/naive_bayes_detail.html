{% extends "tutorial_detail.html" %}

{% block tutorial_content %}
<div class="tutorial-section">
    <h2>📚 What is Naive Bayes?</h2>
    <p>Naive Bayes is a family of probabilistic algorithms based on applying Bayes' theorem with the "naive" assumption of conditional independence between    </div>
</div>

<div class="tutorial-section">
    <h2>🎮 Interactive Demo: Text Classification</h2>
    <div class="example-box">
        <h3>Try the Naive Bayes Classifier</h3>
        <p>Enter some text below and see how a Naive Bayes classifier would categorize it as positive or negative sentiment:</p>
        
        <div style="margin: 1.5rem 0;">
            <label for="text-input" style="display: block; margin-bottom: 0.5rem; font-weight: 600;">Enter text to classify:</label>
            <textarea id="text-input" 
                     placeholder="Type your text here... (e.g., 'I love this movie!' or 'This product is terrible')"
                     style="width: 100%; height: 100px; padding: 1rem; border: 2px solid var(--border-color); border-radius: var(--border-radius-md); font-size: 1rem; resize: vertical;"></textarea>
        </div>
        
        <div style="margin: 1rem 0;">
            <button onclick="classifyText()" style="background: var(--accent-color); color: white; border: none; padding: 0.75rem 1.5rem; border-radius: var(--border-radius-md); font-size: 1rem; cursor: pointer; margin-right: 1rem;">
                Classify Text
            </button>
            <button onclick="resetDemo()" style="background: var(--text-light); color: white; border: none; padding: 0.75rem 1.5rem; border-radius: var(--border-radius-md); font-size: 1rem; cursor: pointer;">
                Reset
            </button>
        </div>
        
        <div id="classification-result" style="margin-top: 1.5rem; padding: 1rem; border-radius: var(--border-radius-md); display: none;">
            <h4>Classification Result:</h4>
            <div id="result-content"></div>
        </div>
        
        <div id="probability-breakdown" style="margin-top: 1rem; display: none;">
            <h5>Probability Breakdown:</h5>
            <div style="display: flex; gap: 1rem; margin-top: 0.5rem;">
                <div style="flex: 1; background: #e8f5e8; padding: 1rem; border-radius: var(--border-radius-md);">
                    <strong>Positive:</strong> <span id="positive-prob">0%</span>
                    <div style="background: #c8e6c9; height: 10px; border-radius: 5px; margin-top: 0.5rem;">
                        <div id="positive-bar" style="background: var(--success-color); height: 100%; border-radius: 5px; width: 0%; transition: width 0.5s ease;"></div>
                    </div>
                </div>
                <div style="flex: 1; background: #fde8e8; padding: 1rem; border-radius: var(--border-radius-md);">
                    <strong>Negative:</strong> <span id="negative-prob">0%</span>
                    <div style="background: #ffcdd2; height: 10px; border-radius: 5px; margin-top: 0.5rem;">
                        <div id="negative-bar" style="background: var(--danger-color); height: 100%; border-radius: 5px; width: 0%; transition: width 0.5s ease;"></div>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="word-analysis" style="margin-top: 1rem; display: none;">
            <h5>Word Impact Analysis:</h5>
            <p style="color: var(--text-secondary); font-size: 0.9rem;">Words that influenced the classification:</p>
            <div id="word-impact" style="margin-top: 0.5rem;"></div>
        </div>
    </div>
</div>

<script>
// Simple Naive Bayes sentiment classifier demo
class NaiveBayesDemo {
    constructor() {
        // Pre-trained word weights (simplified for demo)
        this.positiveWords = {
            'good': 0.8, 'great': 0.9, 'excellent': 0.95, 'amazing': 0.9, 'wonderful': 0.85,
            'fantastic': 0.9, 'love': 0.85, 'perfect': 0.9, 'best': 0.85, 'awesome': 0.9,
            'brilliant': 0.85, 'outstanding': 0.9, 'superb': 0.85, 'nice': 0.7, 'happy': 0.8,
            'pleased': 0.75, 'satisfied': 0.7, 'recommend': 0.75, 'beautiful': 0.8, 'impressive': 0.8
        };
        
        this.negativeWords = {
            'bad': 0.8, 'terrible': 0.9, 'awful': 0.95, 'horrible': 0.9, 'worst': 0.9,
            'hate': 0.85, 'disgusting': 0.9, 'pathetic': 0.85, 'useless': 0.8, 'disappointed': 0.75,
            'poor': 0.7, 'slow': 0.6, 'broken': 0.8, 'wrong': 0.7, 'failed': 0.75,
            'problem': 0.65, 'issue': 0.6, 'error': 0.7, 'waste': 0.8, 'regret': 0.75
        };
        
        this.neutralWords = new Set(['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by']);
    }
    
    preprocessText(text) {
        return text.toLowerCase()
            .replace(/[^\w\s]/g, ' ')
            .split(/\s+/)
            .filter(word => word.length > 0 && !this.neutralWords.has(word));
    }
    
    classify(text) {
        const words = this.preprocessText(text);
        
        let positiveScore = 0.5; // Prior probability
        let negativeScore = 0.5; // Prior probability
        
        const wordImpacts = [];
        
        for (const word of words) {
            let impact = 0;
            let sentiment = 'neutral';
            
            if (this.positiveWords[word]) {
                positiveScore += this.positiveWords[word];
                impact = this.positiveWords[word];
                sentiment = 'positive';
            } else if (this.negativeWords[word]) {
                negativeScore += this.negativeWords[word];
                impact = this.negativeWords[word];
                sentiment = 'negative';
            } else {
                // Unknown word - slight penalty
                positiveScore += 0.1;
                negativeScore += 0.1;
                impact = 0.1;
                sentiment = 'unknown';
            }
            
            wordImpacts.push({ word, impact, sentiment });
        }
        
        // Normalize scores
        const total = positiveScore + negativeScore;
        const positiveProbability = positiveScore / total;
        const negativeProbability = negativeScore / total;
        
        return {
            prediction: positiveProbability > negativeProbability ? 'positive' : 'negative',
            probabilities: {
                positive: positiveProbability,
                negative: negativeProbability
            },
            wordImpacts: wordImpacts.sort((a, b) => b.impact - a.impact)
        };
    }
}

const naiveBayesDemo = new NaiveBayesDemo();

function classifyText() {
    const textInput = document.getElementById('text-input');
    const text = textInput.value.trim();
    
    if (!text) {
        alert('Please enter some text to classify!');
        return;
    }
    
    const result = naiveBayesDemo.classify(text);
    
    // Show result container
    const resultDiv = document.getElementById('classification-result');
    resultDiv.style.display = 'block';
    
    // Update result content
    const resultContent = document.getElementById('result-content');
    const sentiment = result.prediction;
    const confidence = Math.max(result.probabilities.positive, result.probabilities.negative);
    
    resultContent.innerHTML = `
        <div style="display: flex; align-items: center; gap: 1rem;">
            <div style="font-size: 2rem;">${sentiment === 'positive' ? '😊' : '😔'}</div>
            <div>
                <strong style="color: ${sentiment === 'positive' ? 'var(--success-color)' : 'var(--danger-color)'}; font-size: 1.2rem;">
                    ${sentiment.toUpperCase()} SENTIMENT
                </strong>
                <div style="color: var(--text-secondary);">
                    Confidence: ${(confidence * 100).toFixed(1)}%
                </div>
            </div>
        </div>
    `;
    
    // Update probability bars
    document.getElementById('probability-breakdown').style.display = 'block';
    document.getElementById('positive-prob').textContent = `${(result.probabilities.positive * 100).toFixed(1)}%`;
    document.getElementById('negative-prob').textContent = `${(result.probabilities.negative * 100).toFixed(1)}%`;
    
    // Animate bars
    setTimeout(() => {
        document.getElementById('positive-bar').style.width = `${result.probabilities.positive * 100}%`;
        document.getElementById('negative-bar').style.width = `${result.probabilities.negative * 100}%`;
    }, 100);
    
    // Show word analysis
    const wordAnalysis = document.getElementById('word-analysis');
    const wordImpact = document.getElementById('word-impact');
    
    if (result.wordImpacts.length > 0) {
        wordAnalysis.style.display = 'block';
        
        const topWords = result.wordImpacts.slice(0, 8); // Show top 8 words
        wordImpact.innerHTML = topWords.map(word => {
            let color = 'var(--text-light)';
            let icon = '⚪';
            
            if (word.sentiment === 'positive') {
                color = 'var(--success-color)';
                icon = '🟢';
            } else if (word.sentiment === 'negative') {
                color = 'var(--danger-color)';
                icon = '🔴';
            }
            
            return `
                <span style="display: inline-block; margin: 0.25rem; padding: 0.5rem 0.75rem; background: white; border: 2px solid ${color}; border-radius: 20px; color: ${color}; font-size: 0.9rem;">
                    ${icon} ${word.word} (${(word.impact * 100).toFixed(0)}%)
                </span>
            `;
        }).join('');
    }
    
    // Set background color based on sentiment
    if (sentiment === 'positive') {
        resultDiv.style.background = 'linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%)';
        resultDiv.style.border = '2px solid var(--success-color)';
    } else {
        resultDiv.style.background = 'linear-gradient(135deg, #fde8e8 0%, #ffcdd2 100%)';
        resultDiv.style.border = '2px solid var(--danger-color)';
    }
}

function resetDemo() {
    document.getElementById('text-input').value = '';
    document.getElementById('classification-result').style.display = 'none';
    document.getElementById('probability-breakdown').style.display = 'none';
    document.getElementById('word-analysis').style.display = 'none';
    
    // Reset bars
    document.getElementById('positive-bar').style.width = '0%';
    document.getElementById('negative-bar').style.width = '0%';
}

// Add some example texts for quick testing
document.addEventListener('DOMContentLoaded', function() {
    const textInput = document.getElementById('text-input');
    
    // Add example button
    const exampleBtn = document.createElement('button');
    exampleBtn.textContent = 'Try Example';
    exampleBtn.style.cssText = 'background: var(--text-light); color: white; border: none; padding: 0.5rem 1rem; border-radius: var(--border-radius-md); font-size: 0.9rem; cursor: pointer; margin-left: 1rem;';
    
    const examples = [
        "I absolutely love this product! It's amazing and works perfectly.",
        "This is the worst thing I've ever bought. Completely useless and waste of money.",
        "The movie was okay, nothing special but not terrible either.",
        "Outstanding performance! Highly recommend to everyone.",
        "Terrible customer service. Very disappointed with the quality."
    ];
    
    exampleBtn.onclick = function() {
        const randomExample = examples[Math.floor(Math.random() * examples.length)];
        textInput.value = randomExample;
    };
    
    textInput.parentNode.appendChild(exampleBtn);
});
</script>

<div class="tutorial-section">
    <h2>🌍 Real-World Applications</h2>y pair of features. Despite this strong assumption, it works surprisingly well for many real-world problems, especially text classification and spam filtering.</p>
</div>

<div class="tutorial-section">
    <h2>🔢 The Mathematical Foundation</h2>
    <p>Bayes' theorem forms the core of this algorithm:</p>
    
    <div class="formula-box">
        P(A|B) = P(B|A) × P(A) / P(B)
    </div>
    
    <p>For classification, this becomes:</p>
    
    <div class="formula-box">
        P(class|features) = P(features|class) × P(class) / P(features)
    </div>
    
    <p>The "naive" assumption means we assume all features are independent:</p>
    
    <div class="formula-box">
        P(x₁,x₂,...,xₙ|class) = P(x₁|class) × P(x₂|class) × ... × P(xₙ|class)
    </div>
</div>

<div class="tutorial-section">
    <h2>📊 Simple Example: Weather Prediction</h2>
    <div class="example-box">
        <h3>Dataset: Will we play tennis based on weather?</h3>
        <div style="overflow-x: auto;">
            <table style="width: 100%; border-collapse: collapse; margin: 1rem 0;">
                <thead>
                    <tr style="background: var(--accent-color); color: white;">
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Day</th>
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Outlook</th>
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Temperature</th>
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Humidity</th>
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Wind</th>
                        <th style="padding: 0.5rem; border: 1px solid #ddd;">Play Tennis?</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">1</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Sunny</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Hot</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">No</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">2</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Sunny</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Hot</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">No</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">3</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Overcast</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Hot</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">4</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Rain</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">5</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Rain</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Cool</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">6</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Rain</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Cool</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">No</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">7</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Overcast</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Cool</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">8</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Sunny</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">No</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">9</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Sunny</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Cool</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">10</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Rain</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">11</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Sunny</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">12</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Overcast</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">13</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Overcast</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Hot</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Normal</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Weak</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Yes</td></tr>
                    <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">14</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Rain</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Mild</td><td style="padding: 0.5rem; border: 1px solid #ddd;">High</td><td style="padding: 0.5rem; border: 1px solid #ddd;">Strong</td><td style="padding: 0.5rem; border: 1px solid #ddd;">No</td></tr>
                </tbody>
            </table>
        </div>
    </div>

    <h3>Step-by-Step Calculation</h3>
    <p>Let's predict: <strong>Outlook=Sunny, Temperature=Cool, Humidity=High, Wind=Strong</strong></p>
    
    <div class="example-box">
        <h4>🔢 Step 1: Prior Probabilities</h4>
        <p>P(Play=Yes) = 9/14 = <span style="background: #fff9c4; padding: 2px 6px; border-radius: 4px; font-weight: bold;">0.643</span></p>
        <p>P(Play=No) = 5/14 = <span style="background: #fff9c4; padding: 2px 6px; border-radius: 4px; font-weight: bold;">0.357</span></p>
        
        <h4>📊 Step 2: Likelihood Calculations</h4>
        <p><strong>For Play=Yes:</strong></p>
        <ul>
            <li>P(Outlook=Sunny|Yes) = 2/9 = 0.222</li>
            <li>P(Temperature=Cool|Yes) = 3/9 = 0.333</li>
            <li>P(Humidity=High|Yes) = 3/9 = 0.333</li>
            <li>P(Wind=Strong|Yes) = 3/9 = 0.333</li>
        </ul>
        
        <p><strong>For Play=No:</strong></p>
        <ul>
            <li>P(Outlook=Sunny|No) = 3/5 = 0.600</li>
            <li>P(Temperature=Cool|No) = 1/5 = 0.200</li>
            <li>P(Humidity=High|No) = 4/5 = 0.800</li>
            <li>P(Wind=Strong|No) = 3/5 = 0.600</li>
        </ul>
        
        <h4>🎯 Step 3: Final Calculation</h4>
        <p>P(Yes|features) ∝ 0.643 × 0.222 × 0.333 × 0.333 × 0.333 = <span style="background: #fff9c4; padding: 2px 6px; border-radius: 4px; font-weight: bold;">0.0063</span></p>
        <p>P(No|features) ∝ 0.357 × 0.600 × 0.200 × 0.800 × 0.600 = <span style="background: #fff9c4; padding: 2px 6px; border-radius: 4px; font-weight: bold;">0.0206</span></p>
        
        <p><strong>Prediction: <span style="background: #fff9c4; padding: 2px 6px; border-radius: 4px; font-weight: bold;">No (Don't play tennis)</span></strong></p>
    </div>
</div>

<div class="tutorial-section">
    <h2>💻 Python Implementation</h2>
    
    <h3>From Scratch Implementation</h3>
    <div class="code-example">import numpy as np
import pandas as pd
from collections import defaultdict

class NaiveBayesClassifier:
    def __init__(self):
        self.class_probs = {}
        self.feature_probs = defaultdict(lambda: defaultdict(dict))
        self.classes = []
        
    def fit(self, X, y):
        """Train the Naive Bayes classifier"""
        self.classes = np.unique(y)
        n_samples = len(y)
        
        # Calculate class probabilities
        for cls in self.classes:
            self.class_probs[cls] = np.sum(y == cls) / n_samples
        
        # Calculate feature probabilities
        for feature_idx in range(X.shape[1]):
            feature_values = np.unique(X[:, feature_idx])
            
            for cls in self.classes:
                class_mask = (y == cls)
                class_samples = X[class_mask]
                
                for value in feature_values:
                    count = np.sum(class_samples[:, feature_idx] == value)
                    # Add Laplace smoothing
                    self.feature_probs[feature_idx][cls][value] = (
                        (count + 1) / (np.sum(class_mask) + len(feature_values))
                    )
    
    def predict_proba(self, X):
        """Predict class probabilities"""
        predictions = []
        
        for sample in X:
            class_scores = {}
            
            for cls in self.classes:
                # Start with class prior
                score = self.class_probs[cls]
                
                # Multiply by feature likelihoods
                for feature_idx, feature_value in enumerate(sample):
                    if feature_value in self.feature_probs[feature_idx][cls]:
                        score *= self.feature_probs[feature_idx][cls][feature_value]
                    else:
                        # Laplace smoothing for unseen values
                        score *= 1 / (
                            np.sum([1 for y_val in self.classes]) + 
                            len(self.feature_probs[feature_idx][cls])
                        )
                
                class_scores[cls] = score
            
            # Normalize probabilities
            total = sum(class_scores.values())
            class_probs = {cls: score/total for cls, score in class_scores.items()}
            predictions.append(class_probs)
        
        return predictions
    
    def predict(self, X):
        """Predict classes"""
        probabilities = self.predict_proba(X)
        return [max(prob_dict, key=prob_dict.get) for prob_dict in probabilities]

# Example usage
weather_data = [
    ['Sunny', 'Hot', 'High', 'Weak', 'No'],
    ['Sunny', 'Hot', 'High', 'Strong', 'No'],
    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],
    # ... more data rows
]

# Convert to numpy arrays
X = np.array([row[:-1] for row in weather_data])
y = np.array([row[-1] for row in weather_data])

# Train the classifier
nb = NaiveBayesClassifier()
nb.fit(X, y)

# Make predictions
test_sample = [['Sunny', 'Cool', 'High', 'Strong']]
prediction = nb.predict(test_sample)
probabilities = nb.predict_proba(test_sample)

print(f"Prediction: {prediction[0]}")
print(f"Probabilities: {probabilities[0]}")</div>
    
    <h3>Using Scikit-learn</h3>
    <div class="code-example">from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# For categorical data (like our weather example)
def categorical_naive_bayes_example():
    # Encode categorical features
    encoders = {}
    X_encoded = np.zeros((len(X), X.shape[1]))
    
    for i in range(X.shape[1]):
        encoders[i] = LabelEncoder()
        X_encoded[:, i] = encoders[i].fit_transform(X[:, i])
    
    # Encode target
    y_encoder = LabelEncoder()
    y_encoded = y_encoder.fit_transform(y)
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_encoded, y_encoded, test_size=0.3, random_state=42
    )
    
    # Train model
    model = CategoricalNB()
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    
    # Evaluation
    print("Accuracy:", model.score(X_test, y_test))
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=y_encoder.classes_))
    
    return model, encoders, y_encoder

# For continuous data (Gaussian Naive Bayes)
def gaussian_naive_bayes_example():
    from sklearn.datasets import load_iris
    
    # Load iris dataset
    iris = load_iris()
    X, y = iris.data, iris.target
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    # Train model
    model = GaussianNB()
    model.fit(X_train, y_train)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X, y, cv=5)
    
    print(f"Gaussian NB Accuracy: {model.score(X_test, y_test):.3f}")
    print(f"Cross-validation scores: {cv_scores}")
    print(f"Mean CV accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    
    return model</div>
</div>

<div class="tutorial-section">
    <h2>⚖️ Advantages and Disadvantages</h2>
    
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin: 2rem 0;">
        <div style="background: linear-gradient(135deg, #d4edda, #c3e6cb); border: 2px solid #28a745; border-radius: 12px; padding: 25px;">
            <h3 style="color: #155724; margin-bottom: 1rem;">✅ Advantages</h3>
            <ul class="feature-list">
                <li>Simple and fast algorithm</li>
                <li>Works well with small datasets</li>
                <li>Handles multiple classes naturally</li>
                <li>Good baseline for text classification</li>
                <li>Not sensitive to irrelevant features</li>
                <li>Good performance with categorical inputs</li>
            </ul>
        </div>
        
        <div style="background: linear-gradient(135deg, #ffebee, #f8d7da); border: 2px solid #dc3545; border-radius: 12px; padding: 25px;">
            <h3 style="color: #721c24; margin-bottom: 1rem;">❌ Disadvantages</h3>
            <ul class="feature-list">
                <li>Strong independence assumption</li>
                <li>Can be outperformed by more sophisticated methods</li>
                <li>Categorical inputs require Laplace smoothing</li>
                <li>Poor estimator for probability</li>
                <li>Sensitive to skewed data</li>
                <li>Limited expressiveness</li>
            </ul>
        </div>
    </div>
</div>

<div class="tutorial-section">
    <h2>🎯 Real-World Applications</h2>
    
    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin: 20px 0;">
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>📧 Email Spam Detection</h4>
            <p>Classifying emails as spam or not spam based on word frequencies and other features.</p>
        </div>
        
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>💭 Sentiment Analysis</h4>
            <p>Determining sentiment (positive/negative) from text reviews and social media posts.</p>
        </div>
        
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>🏥 Medical Diagnosis</h4>
            <p>Assisting in medical diagnosis based on symptoms and patient history.</p>
        </div>
        
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>📰 News Classification</h4>
            <p>Categorizing news articles into different topics or categories.</p>
        </div>
        
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>🛡️ Fraud Detection</h4>
            <p>Identifying potentially fraudulent transactions in financial systems.</p>
        </div>
        
        <div style="background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #3498db;">
            <h4>🔍 Web Search</h4>
            <p>Ranking and filtering search results based on relevance.</p>
        </div>
    </div>
</div>

<div class="tutorial-section">
    <h2>🚀 Next Steps</h2>
    <div class="example-box">
        <h3>Continue Your Learning Journey</h3>
        <ul>
            <li><strong>Practice Implementation:</strong> Try implementing Naive Bayes from scratch on different datasets</li>
            <li><strong>Explore Variants:</strong> Learn about Gaussian, Multinomial, and Bernoulli Naive Bayes</li>
            <li><strong>Advanced Topics:</strong> Study feature selection and text preprocessing techniques</li>
            <li><strong>Compare Algorithms:</strong> Compare Naive Bayes with other classification methods</li>
        </ul>
        
        <div style="margin-top: 1.5rem;">
            <a href="{{ url_for('tutorial_detail', slug='decision-trees') }}" class="btn btn-primary" style="margin-right: 1rem;">Next: Decision Trees</a>
            <a href="{{ url_for('tutorials_list') }}" class="btn btn-secondary">All Tutorials</a>
        </div>
    </div>
</div>
{% endblock %}
