<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decision Trees - ML Tutorial</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Tree-based learning algorithm for classification and regression">
    <meta name="keywords" content="machine learning, artificial intelligence, data science, python, portfolio">
    <meta name="author" content="Alireza Barzin Zanganeh">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost/tutorials/decision-trees">
    <meta property="og:title" content="Decision Trees - ML Tutorial">
    <meta property="og:description" content="Tree-based learning algorithm for classification and regression">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="http://localhost/tutorials/decision-trees">
    <meta property="twitter:title" content="Decision Trees - ML Tutorial">
    <meta property="twitter:description" content="Tree-based learning algorithm for classification and regression">
    
    <!-- CSS -->
    <link href="/static/css/main.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    
<style>
.tutorial-content {
    max-width: 1000px;
    margin: 0 auto;
}

.tutorial-header {
    background: var(--gradient-primary);
    color: white;
    padding: 3rem 0;
    text-align: center;
    margin-bottom: 2rem;
}

.tutorial-meta {
    display: flex;
    justify-content: center;
    gap: 1rem;
    margin-top: 1rem;
    flex-wrap: wrap;
}

.tutorial-body {
    background: white;
    padding: 2rem;
    border-radius: var(--border-radius-lg);
    box-shadow: var(--shadow-lg);
    margin-bottom: 2rem;
}

.tutorial-section {
    margin-bottom: 2rem;
}

.tutorial-section h2 {
    color: var(--primary-color);
    border-bottom: 2px solid var(--accent-color);
    padding-bottom: 0.5rem;
    margin-bottom: 1rem;
}

.tutorial-section h3 {
    color: var(--secondary-color);
    margin-top: 2rem;
    margin-bottom: 1rem;
}

.code-example {
    background: var(--bg-dark);
    color: #E2E8F0;
    padding: 1.5rem;
    border-radius: var(--border-radius-md);
    margin: 1rem 0;
    font-family: var(--font-family-mono);
    font-size: 0.9rem;
    overflow-x: auto;
    position: relative;
    white-space: pre-wrap;
    word-wrap: break-word;
}

.code-example::before {
    content: 'Python';
    position: absolute;
    top: 0.5rem;
    right: 1rem;
    background: var(--accent-color);
    color: white;
    padding: 0.25rem 0.5rem;
    border-radius: var(--border-radius-sm);
    font-size: 0.7rem;
    font-weight: 600;
}

.formula-box {
    background: linear-gradient(135deg, #f0f8ff 0%, #e6f3ff 100%);
    border-left: 4px solid var(--accent-color);
    padding: 1rem;
    margin: 1rem 0;
    border-radius: var(--border-radius-md);
    font-style: italic;
    text-align: center;
}

.example-box {
    background: var(--bg-secondary);
    border: 1px solid var(--border-color);
    border-radius: var(--border-radius-md);
    padding: 1.5rem;
    margin: 1rem 0;
}

.navigation-box {
    background: var(--bg-secondary);
    padding: 1.5rem;
    border-radius: var(--border-radius-lg);
    text-align: center;
    margin-top: 2rem;
}

.interactive-demo {
    background: white;
    border: 2px solid var(--accent-color);
    border-radius: var(--border-radius-lg);
    padding: 1.5rem;
    margin: 2rem 0;
}

ul.feature-list {
    list-style: none;
    padding: 0;
}

ul.feature-list li {
    padding: 0.5rem 0;
    border-bottom: 1px solid var(--border-color);
}

ul.feature-list li:before {
    content: '✓';
    color: var(--success-color);
    font-weight: bold;
    margin-right: 0.5rem;
}

@media (max-width: 768px) {
    .tutorial-body {
        padding: 1rem;
    }
    
    .tutorial-meta {
        flex-direction: column;
        align-items: center;
    }
}
</style>

</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <a href="/">Alireza Barzin Zanganeh</a>
            </div>
            <div class="nav-menu" id="nav-menu">
                <a href="/" class="nav-link">Home</a>
                <a href="/#about" class="nav-link">About</a>
                <a href="/tutorials" class="nav-link">Tutorials</a>
                <a href="/projects" class="nav-link">Projects</a>
                <a href="/#contact" class="nav-link">Contact</a>
            </div>
            <div class="nav-toggle" id="mobile-menu">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
        
<div class="tutorial-content">
    <!-- Tutorial Header -->
    <div class="tutorial-header">
        <div class="container">
            <h1>Decision Trees</h1>
            <p>Tree-based learning algorithm for classification and regression</p>
            <div class="tutorial-meta">
                <span class="badge badge-success">Beginner</span>
                <span class="badge badge-secondary">20 min read</span>
                
                <span class="badge badge-primary">classification</span>
                
                <span class="badge badge-primary">regression</span>
                
                <span class="badge badge-primary">interpretable</span>
                
                <span class="badge badge-primary">beginner</span>
                
            </div>
        </div>
    </div>

    <!-- Tutorial Content -->
    <div class="container">
        <div class="tutorial-body">
            
<div class="tutorial-section">
    <h2>Introduction to Decision Trees</h2>
    <p>
        Decision trees are versatile machine learning algorithms that can be used for both classification 
        and regression tasks. They work by recursively splitting the data based on feature values to 
        create a tree-like model of decisions that leads to predictions.
    </p>
    
    <div class="highlight-box">
        <h3>🌳 Why Decision Trees?</h3>
        <ul>
            <li><strong>Interpretable:</strong> Easy to understand and visualize</li>
            <li><strong>No assumptions:</strong> Don't require linear relationships</li>
            <li><strong>Handle mixed data:</strong> Work with numerical and categorical features</li>
            <li><strong>Feature selection:</strong> Automatically identify important features</li>
            <li><strong>Non-parametric:</strong> No assumptions about data distribution</li>
        </ul>
    </div>
</div>

<div class="tutorial-section">
    <h2>How Decision Trees Work</h2>
    
    <h3>The Tree Building Process</h3>
    <ol>
        <li><strong>Root Node:</strong> Start with the entire dataset</li>
        <li><strong>Feature Selection:</strong> Choose the best feature to split on</li>
        <li><strong>Splitting:</strong> Divide data based on feature threshold</li>
        <li><strong>Recursion:</strong> Repeat process for each subset</li>
        <li><strong>Stopping:</strong> Stop when criteria are met (depth, purity, etc.)</li>
    </ol>

    <h3>Splitting Criteria</h3>
    
    <h4>For Classification Trees:</h4>
    <div class="formula-box">
        <strong>Gini Impurity:</strong> Gini = 1 - Σ(pᵢ)²<br>
        <strong>Entropy:</strong> Entropy = -Σ(pᵢ × log₂(pᵢ))<br>
        <strong>Information Gain:</strong> IG = Entropy(parent) - Σ(weighted Entropy(children))
    </div>

    <h4>For Regression Trees:</h4>
    <div class="formula-box">
        <strong>Mean Squared Error:</strong> MSE = Σ(yᵢ - ȳ)² / n<br>
        <strong>Mean Absolute Error:</strong> MAE = Σ|yᵢ - ȳ| / n
    </div>
</div>

<div class="tutorial-section">
    <h2>Implementation Example</h2>
    <p>Here's how to implement decision trees using scikit-learn:</p>
    
    <div class="code-example">import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error
from sklearn.tree import plot_tree, export_text
import matplotlib.pyplot as plt

# Load and prepare data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Classification Tree
clf_tree = DecisionTreeClassifier(
    criterion='gini',           # or 'entropy'
    max_depth=5,               # limit tree depth
    min_samples_split=20,      # minimum samples to split
    min_samples_leaf=10,       # minimum samples in leaf
    random_state=42
)

# Train the model
clf_tree.fit(X_train, y_train)

# Make predictions
y_pred = clf_tree.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Feature importance
feature_importance = clf_tree.feature_importances_
for i, importance in enumerate(feature_importance):
    print(f"Feature {i}: {importance:.4f}")

# Visualize the tree
plt.figure(figsize=(15, 10))
plot_tree(clf_tree, max_depth=3, filled=True, feature_names=feature_names, class_names=class_names)
plt.title("Decision Tree Visualization")
plt.show()

# Text representation
tree_rules = export_text(clf_tree, feature_names=feature_names)
print("Decision Tree Rules:")
print(tree_rules)</div>
</div>

<div class="tutorial-section">
    <h2>Advantages and Disadvantages</h2>
    
    <div class="pros-cons-grid">
        <div class="pros-box">
            <h3>✅ Advantages</h3>
            <ul>
                <li>Easy to understand and interpret</li>
                <li>Requires little data preparation</li>
                <li>Handles both numerical and categorical data</li>
                <li>Can model non-linear relationships</li>
                <li>Automatic feature selection</li>
                <li>Can handle missing values</li>
                <li>Robust to outliers</li>
            </ul>
        </div>
        
        <div class="cons-box">
            <h3>❌ Disadvantages</h3>
            <ul>
                <li>Prone to overfitting</li>
                <li>Unstable (small data changes = different trees)</li>
                <li>Biased toward features with more levels</li>
                <li>Can create overly complex trees</li>
                <li>Difficulty with linear relationships</li>
                <li>Can be biased with imbalanced datasets</li>
            </ul>
        </div>
    </div>
</div>

<div class="tutorial-section">
    <h2>Hyperparameter Tuning</h2>
    
    <h3>Key Parameters</h3>
    <ul>
        <li><strong>max_depth:</strong> Maximum depth of the tree</li>
        <li><strong>min_samples_split:</strong> Minimum samples required to split</li>
        <li><strong>min_samples_leaf:</strong> Minimum samples required in a leaf</li>
        <li><strong>max_features:</strong> Number of features to consider for splits</li>
        <li><strong>criterion:</strong> Splitting criterion (gini, entropy, mse)</li>
    </ul>

    <div class="code-example">from sklearn.model_selection import GridSearchCV

# Parameter grid
param_grid = {
    'max_depth': [3, 5, 7, 10, None],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 2, 5, 10],
    'criterion': ['gini', 'entropy']
}

# Grid search with cross-validation
grid_search = GridSearchCV(
    DecisionTreeClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score:", grid_search.best_score_)

# Use best model
best_tree = grid_search.best_estimator_
y_pred_best = best_tree.predict(X_test)
print("Test accuracy:", accuracy_score(y_test, y_pred_best))</div>
</div>

<div class="tutorial-section">
    <h2>Ensemble Methods</h2>
    <p>Decision trees are often used as building blocks for more powerful ensemble methods:</p>
    
    <div class="ensemble-grid">
        <div class="ensemble-method">
            <h3>🌲 Random Forest</h3>
            <p>Combines multiple decision trees with random feature selection</p>
            <ul>
                <li>Reduces overfitting</li>
                <li>Provides feature importance</li>
                <li>Handles large datasets well</li>
            </ul>
        </div>
        
        <div class="ensemble-method">
            <h3>⚡ Gradient Boosting</h3>
            <p>Sequentially builds trees to correct previous mistakes</p>
            <ul>
                <li>High predictive accuracy</li>
                <li>Works well with different data types</li>
                <li>Includes XGBoost, LightGBM, CatBoost</li>
            </ul>
        </div>
        
        <div class="ensemble-method">
            <h3>🎯 AdaBoost</h3>
            <p>Adaptive boosting that focuses on misclassified examples</p>
            <ul>
                <li>Good for binary classification</li>
                <li>Reduces bias and variance</li>
                <li>Less prone to overfitting</li>
            </ul>
        </div>
    </div>
</div>

<div class="tutorial-section">
    <h2>🚀 Next Steps</h2>
    <div class="example-box">
        <h3>Continue Your Learning Journey</h3>
        <ul>
            <li><strong>Practice:</strong> Implement decision trees on different datasets</li>
            <li><strong>Ensemble Methods:</strong> Learn Random Forest and Gradient Boosting</li>
            <li><strong>Visualization:</strong> Practice interpreting tree structures</li>
            <li><strong>Feature Engineering:</strong> Improve model performance with better features</li>
        </ul>
        
        <div style="margin-top: 1.5rem;">
            <a href="../tutorials/neural-networks.html" class="btn btn-primary" style="margin-right: 1rem;">Next: Neural Networks</a>
            <a href="/tutorials" class="btn btn-secondary">All Tutorials</a>
        </div>
    </div>
</div>

        </div>

        <!-- Navigation -->
        <div class="navigation-box">
            <a href="/tutorials" class="btn btn-secondary" style="margin-right: 1rem;">
                <i class="fas fa-arrow-left"></i> All Tutorials
            </a>
            <a href="/" class="btn btn-primary">
                <i class="fas fa-home"></i> Home
            </a>
        </div>
    </div>
</div>

    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>Alireza Barzin Zanganeh</h3>
                    <p>Machine Learning Engineer</p>
                </div>
                <div class="footer-section">
                    <h4>Quick Links</h4>
                    <ul>
                        <li><a href="/tutorials">Tutorials</a></li>
                        <li><a href="/projects">Projects</a></li>
                        <li><a href="/#about">About</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Connect</h4>
                    <div class="social-links">
                        <a href="#" class="social-link"><i class="fab fa-github"></i></a>
                        <a href="#" class="social-link"><i class="fab fa-linkedin"></i></a>
                        <a href="#" class="social-link"><i class="fab fa-twitter"></i></a>
                    </div>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 Alireza Barzin Zanganeh. Built with Flask and Python.</p>
            </div>
        </div>
    </footer>

    <!-- JavaScript -->
    <script src="/static/js/main.js"></script>
    
<script>
// Add smooth scrolling for table of contents
document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
            target.scrollIntoView({
                behavior: 'smooth',
                block: 'start'
            });
        }
    });
});

// Highlight code blocks
document.querySelectorAll('.code-example').forEach(block => {
    // Add copy button
    const copyBtn = document.createElement('button');
    copyBtn.textContent = 'Copy';
    copyBtn.className = 'btn btn-secondary';
    copyBtn.style.position = 'absolute';
    copyBtn.style.top = '0.5rem';
    copyBtn.style.left = '1rem';
    copyBtn.style.fontSize = '0.7rem';
    copyBtn.style.padding = '0.25rem 0.5rem';
    
    copyBtn.addEventListener('click', () => {
        navigator.clipboard.writeText(block.textContent);
        copyBtn.textContent = 'Copied!';
        setTimeout(() => copyBtn.textContent = 'Copy', 2000);
    });
    
    block.style.position = 'relative';
    block.appendChild(copyBtn);
});
</script>

</body>
</html>