<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decision Trees Guide - Learning Resources</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
    <link rel="stylesheet" href="../../assets/css/decision_tree_regression.css">
   
</head>
<body>
    <div style="
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
        color: white;
        padding: 12px 20px;
        text-align: center;
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        z-index: 1000;
        box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        font-size: 14px;
        border-bottom: 2px solid rgba(255,255,255,0.2);
    ">
        <span style="margin-right: 10px;">üöß</span>
        <strong>Website Under Development:</strong> 
        We experienced some downtime recently. Some links may be broken and topics incomplete - working to fix everything gradually. 
        <span style="margin-left: 10px;">Thank you for your patience! üôè</span>
        <button onclick="this.parentElement.style.display='none'" style="
            background: rgba(255,255,255,0.2);
            border: none;
            color: white;
            margin-left: 15px;
            padding: 4px 8px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
        ">‚úï</button>
    </div>

    <header class="azbn-header" style="top: 50px;">
        <nav class="azbn-nav" style="top: 50px;">
            <div class="azbn-container" style="display: flex; justify-content: space-between; align-items: center;">
                <a href="../" style="text-decoration: none; color: #4f46e5; display: flex; align-items: center; gap: 0.5rem;">
                    <img src="../../assets/images/logo.png" alt="Logo" style="height: 40px;">
                </a>

                <div class="azbn-links">
                    <a href="../../#home">Home</a>
                    <a href="../../#about">About</a>
                    <a href="../../tutorials/">Tutorials</a>
                    <a href="../../#projects">Projects</a>
                    <a href="../../#contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <!-- Main Content -->
    <main style="padding-top: 150px;">
        <div class="learning-header">
            <div class="container">
                <h1>üå≥ Decision Trees</h1>
                <p>Understanding tree-based algorithms and ensemble methods</p>
            </div>
        </div>

        <div class="container">

            <div class="content-section">
                <h2>Introduction to Decision Trees</h2>
                <p>
                    Decision trees are a type of supervised learning algorithm that can be used for both classification 
                    and regression tasks. They work by creating a model that predicts the value of a target variable 
                    by learning simple decision rules inferred from the data features. The tree structure represents 
                    decisions and their possible consequences.
                </p>
                
                <h3>Key Characteristics</h3>
                <ul>
                    <li><strong>Interpretable:</strong> Easy to understand and visualize</li>
                    <li><strong>Non-parametric:</strong> No assumptions about data distribution</li>
                    <li><strong>Handles mixed data:</strong> Works with both numerical and categorical features</li>
                    <li><strong>Feature selection:</strong> Automatically identifies important features</li>
                </ul>
            </div>

            <div class="content-section">
                <h2>How Decision Trees Work</h2>
                
                <h3>Tree Structure</h3>
                <ul>
                    <li><strong>Root Node:</strong> The topmost node representing the entire dataset</li>
                    <li><strong>Internal Nodes:</strong> Nodes with decision rules (splits)</li>
                    <li><strong>Leaf Nodes:</strong> Terminal nodes with final predictions</li>
                    <li><strong>Branches:</strong> Connections representing outcomes of decisions</li>
                </ul>

                <h3>Splitting Criteria</h3>
                <p>For classification tasks:</p>
                <ul>
                    <li><strong>Gini Impurity:</strong> Measures probability of incorrect classification</li>
                    <li><strong>Entropy:</strong> Measures disorder or randomness in the data</li>
                    <li><strong>Information Gain:</strong> Reduction in entropy after a split</li>
                </ul>

                <div class="formula">
                    Gini Impurity = 1 - Œ£(p_i)¬≤ <br>
                    Entropy = -Œ£(p_i √ó log‚ÇÇ(p_i)) <br>
                    Information Gain = Entropy(parent) - Œ£(weighted_avg √ó Entropy(children))
                </div>
            </div>

            <div class="content-section">
                <h2>Implementation Example</h2>
                <p>Here's a simple decision tree implementation using scikit-learn:</p>
                
                <div class="code-block">
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Load and prepare data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
dt_model = DecisionTreeClassifier(
    criterion='gini',        # or 'entropy'
    max_depth=5,            # prevent overfitting
    min_samples_split=10,   # minimum samples to split
    min_samples_leaf=5,     # minimum samples in leaf
    random_state=42
)

dt_model.fit(X_train, y_train)

# Make predictions
y_pred = dt_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print(classification_report(y_test, y_pred))

# Display tree rules (text format)
tree_rules = export_text(dt_model, feature_names=feature_names)
print(tree_rules)
                </div>
            </div>

            <div class="content-section">
                <h2>Ensemble Methods</h2>
                
                <h3>Random Forest</h3>
                <p>
                    Combines multiple decision trees using bootstrap aggregating (bagging). Each tree is trained 
                    on a random subset of data and features, reducing overfitting and improving generalization.
                </p>

                <h3>Gradient Boosting</h3>
                <p>
                    Builds trees sequentially, where each new tree corrects errors made by previous trees. 
                    Popular implementations include XGBoost, LightGBM, and CatBoost.
                </p>

                <div class="code-block">
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Gradient Boosting
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
                </div>
            </div>

            <div class="content-section">
                <h2>Advantages and Disadvantages</h2>
                
                <h3>Advantages</h3>
                <ul>
                    <li>Easy to understand and interpret</li>
                    <li>Requires little data preparation</li>
                    <li>Handles both numerical and categorical data</li>
                    <li>Can model non-linear relationships</li>
                    <li>Automatic feature selection</li>
                    <li>Missing values handling</li>
                </ul>

                <h3>Disadvantages</h3>
                <ul>
                    <li>Prone to overfitting (especially deep trees)</li>
                    <li>Unstable - small changes in data can result in different trees</li>
                    <li>Biased toward features with more levels</li>
                    <li>Poor performance on linear relationships</li>
                    <li>Difficulty handling missing values in some implementations</li>
                </ul>
            </div>

            <div class="content-section">
                <h2>Best Practices</h2>
                <ul>
                    <li><strong>Pruning:</strong> Use max_depth, min_samples_split to prevent overfitting</li>
                    <li><strong>Cross-validation:</strong> Use k-fold CV to evaluate model performance</li>
                    <li><strong>Feature importance:</strong> Analyze which features are most important</li>
                    <li><strong>Ensemble methods:</strong> Use Random Forest or Gradient Boosting for better performance</li>
                    <li><strong>Data preprocessing:</strong> Handle missing values and outliers appropriately</li>
                    <li><strong>Visualization:</strong> Plot the tree to understand decision rules</li>
                </ul>
            </div>

            <a href="../../tutorials" class="back-link">‚Üê Back to Tutorials</a>
        </div>
    </main>

    <script>
        // Header background change on scroll
        window.addEventListener('scroll', function() {
            const header = document.querySelector('header');
            if (window.scrollY > 50) {
                header.style.background = 'rgba(255, 255, 255, 0.95)';
                header.style.color = '#333';
            } else {
                header.style.background = 'rgba(255, 255, 255, 0.1)';
                header.style.color = 'white';
            }
        });
    </script>
</body>
</html>
