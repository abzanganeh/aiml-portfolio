<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 1: ML Introduction - Ali Zanganeh</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
</head>
<body>
    <header class="azbn-header">
        <div class="azbn-container">
            <h1><a href="../../" style="text-decoration: none; color: #4f46e5;">Ali Zanganeh</a></h1>
            <nav>
                <a href="../../#home">Home</a>
                <a href="../">Tutorials</a>
                <a href="./">ML Fundamentals</a>
            </nav>
        </div>
    </header>

    <main style="padding-top: 100px;">
        <section class="azbn-section">
            <div class="azbn-container">
                <h1>Chapter 1: What is Machine Learning?</h1>
                
                <h2>üéØ Learning Objectives</h2>
                <ul class="azbn-skills">
                    <li>Understand core ML concepts and terminology</li>
                    <li>Distinguish between supervised, unsupervised, and reinforcement learning</li>
                    <li>Implement basic data exploration with Python</li>
                    <li>Set up your ML development environment</li>
                </ul>

                <h2>üìö Theory: Types of Machine Learning</h2>
                <div class="azbn-card">
                    <h3>üéì Supervised Learning</h3>
                    <p><strong>Definition:</strong> Learning with labeled examples (input-output pairs)</p>
                    <p><strong>Examples:</strong> Email spam detection, house price prediction, medical diagnosis</p>
                    <p><strong>Goal:</strong> Learn a function that maps inputs to correct outputs</p>
                </div>

                <div class="azbn-card">
                    <h3>üîç Unsupervised Learning</h3>
                    <p><strong>Definition:</strong> Finding patterns in data without labels</p>
                    <p><strong>Examples:</strong> Customer segmentation, anomaly detection, data compression</p>
                    <p><strong>Goal:</strong> Discover hidden structures in data</p>
                </div>

                <h2>üíª Hands-On Code: Environment Setup</h2>
                <pre style="background: #f4f4f4; padding: 1rem; border-radius: 8px; overflow-x: auto;"><code># -*- coding: utf-8 -*-
"""
Chapter 1: Machine Learning Introduction
Author: Ali Barzin Zanganeh
Purpose: Complete ML fundamentals with practical examples
"""

# Essential imports for machine learning
import numpy as np              # Numerical computations
import pandas as pd             # Data manipulation and analysis
import matplotlib.pyplot as plt # Data visualization
import seaborn as sns          # Advanced statistical visualization
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris, load_boston
import warnings
warnings.filterwarnings('ignore')

# Set up plotting style for professional visualizations
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("üöÄ Machine Learning Environment Ready!")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")

# ==========================================
# SECTION 1: Understanding Data Types in ML
# ==========================================

def explore_ml_data_types():
    """
    Comprehensive guide to data types in machine learning
    
    Key Concepts:
    - Numerical vs Categorical data
    - Features vs Target variables
    - Training vs Test data
    """
    
    print("\n" + "="*50)
    print("üìä DATA TYPES IN MACHINE LEARNING")
    print("="*50)
    
    # Load the famous Iris dataset for demonstration
    iris = load_iris()
    
    # Convert to pandas DataFrame for easier manipulation
    # TIP: Always use DataFrames for real-world ML projects
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['species'] = iris.target_names[iris.target]
    
    print("üå∏ IRIS DATASET OVERVIEW:")
    print(f"Shape: {df.shape} (rows, columns)")
    print(f"Features: {list(df.columns[:-1])}")
    print(f"Target: {df.columns[-1]}")
    
    # Display first few rows
    print("\nFirst 5 rows:")
    print(df.head())
    
    # Data types analysis
    print("\nüìã DATA TYPES:")
    print(df.dtypes)
    
    # Statistical summary
    print("\nüìà STATISTICAL SUMMARY:")
    print(df.describe())
    
    return df

# ==========================================
# SECTION 2: Supervised Learning Example
# ==========================================

def supervised_learning_demo(df):
    """
    Complete supervised learning workflow demonstration
    
    Steps:
    1. Data preparation
    2. Train-test split
    3. Feature scaling
    4. Model training (simple classifier)
    5. Evaluation
    """
    
    print("\n" + "="*50)
    print("üéì SUPERVISED LEARNING DEMONSTRATION")
    print("="*50)
    
    # Prepare features (X) and target (y)
    # X = input features, y = what we want to predict
    X = df.iloc[:, :-1].values  # All columns except last
    y = df.iloc[:, -1].values   # Last column (species)
    
    print(f"Features shape: {X.shape}")
    print(f"Target shape: {y.shape}")
    print(f"Unique classes: {np.unique(y)}")
    
    # Train-test split (80% training, 20% testing)
    # CRITICAL: Never test on training data!
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nTraining set: {X_train.shape[0]} samples")
    print(f"Test set: {X_test.shape[0]} samples")
    
    # Feature scaling - important for many ML algorithms
    # StandardScaler: (x - mean) / std_deviation
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)  # Use same scaling as training
    
    print("\n‚úÖ Data preprocessing completed!")
    print("Next: Train your first ML model in Chapter 2")
    
    return X_train_scaled, X_test_scaled, y_train, y_test

# ==========================================
# SECTION 3: Data Visualization Fundamentals
# ==========================================

def create_ml_visualizations(df):
    """
    Essential data visualization techniques for ML
    
    Visualizations covered:
    - Distribution plots
    - Correlation heatmaps
    - Pairwise feature relationships
    - Class distribution
    """
    
    print("\n" + "="*50)
    print("üìä DATA VISUALIZATION FOR ML")
    print("="*50)
    
    # Create subplots for multiple visualizations
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Machine Learning Data Analysis', fontsize=16, fontweight='bold')
    
    # 1. Feature distributions
    df.iloc[:, :-1].hist(bins=20, ax=axes[0,0])
    axes[0,0].set_title('Feature Distributions')
    
    # 2. Correlation heatmap
    correlation_matrix = df.iloc[:, :-1].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', ax=axes[0,1])
    axes[0,1].set_title('Feature Correlations')
    
    # 3. Class distribution
    class_counts = df['species'].value_counts()
    axes[1,0].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')
    axes[1,0].set_title('Class Distribution')
    
    # 4. Pairwise relationships
    # Using first two features for simplicity
    for species in df['species'].unique():
        species_data = df[df['species'] == species]
        axes[1,1].scatter(species_data.iloc[:, 0], species_data.iloc[:, 1], 
                         label=species, alpha=0.7)
    axes[1,1].set_xlabel(df.columns[0])
    axes[1,1].set_ylabel(df.columns[1])
    axes[1,1].set_title('Feature Relationships by Class')
    axes[1,1].legend()
    
    plt.tight_layout()
    plt.savefig('ml_data_analysis.png', dpi=300, bbox_inches='tight')
    print("üìà Visualizations saved as 'ml_data_analysis.png'")
    
    return fig

# ==========================================
# MAIN EXECUTION
# ==========================================

if __name__ == "__main__":
    print("üéì CHAPTER 1: MACHINE LEARNING INTRODUCTION")
    print("=" * 60)
    
    # Step 1: Explore data types
    iris_df = explore_ml_data_types()
    
    # Step 2: Demonstrate supervised learning workflow
    X_train, X_test, y_train, y_test = supervised_learning_demo(iris_df)
    
    # Step 3: Create visualizations
    fig = create_ml_visualizations(iris_df)
    
    print("\n" + "="*60)
    print("‚úÖ CHAPTER 1 COMPLETED!")
    print("üí° KEY TAKEAWAYS:")
    print("- Machine learning works with numerical data")
    print("- Always split data into training and testing sets")
    print("- Feature scaling improves algorithm performance")
    print("- Visualization helps understand your data")
    print("\nüîú NEXT: Chapter 2 - Regression Algorithms")
    print("="*60)</code></pre>

                <h2>üéØ Key Takeaways</h2>
                <div class="azbn-deployment-status">
                    <p><strong>‚úÖ Concepts Learned:</strong></p>
                    <p>‚Ä¢ Supervised vs Unsupervised learning</p>
                    <p>‚Ä¢ Data preprocessing importance</p>
                    <p>‚Ä¢ Train-test split methodology</p>
                    <p>‚Ä¢ Feature scaling techniques</p>
                </div>

                <div style="margin: 2rem 0; text-align: center;">
                    <a href="./chapter2.html" class="azbn-btn" style="text-decoration: none;">Next: Chapter 2 - Regression ‚Üí</a>
                </div>
            </div>
        </section>
    </main>
</body>
</html>
